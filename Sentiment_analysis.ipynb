{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1dbda04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to C:\\Users\\Aparna\n",
      "[nltk_data]     Shankar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Aparna\n",
      "[nltk_data]     Shankar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Aparna\n",
      "[nltk_data]     Shankar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to C:\\Users\\Aparna\n",
      "[nltk_data]     Shankar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries for text processing, sentiment analysis, and machine learning.\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, sentiwordnet as swn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import spacy\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('sentiwordnet')\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad56ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stop words and lemmatizer.\n",
    "# Define a function for preprocessing text data, which includes:\n",
    "# - Removing URLs, mentions, hashtags, and special characters\n",
    "# - Converting text to lowercase\n",
    "# - Tokenizing, removing stop words, and lemmatizing tokens\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)  # Remove URLs\n",
    "    tweet = re.sub(r\"@\\w+\", \"\", tweet)    # Remove mentions\n",
    "    tweet = re.sub(r\"#\\w+\", \"\", tweet)    # Remove hashtags\n",
    "    tweet = re.sub(r\"[^\\w\\s]\", \"\", tweet) # Remove special characters\n",
    "    tweet = tweet.lower()                     # Convert to lowercase\n",
    "    tokens = word_tokenize(tweet)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatize the tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31c3baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to classify text as subjective or objective based on SentiWordNet.\n",
    "# For each token, check its positive and negative sentiment scores using SentiWordNet.\n",
    "# If a word has a positive or negative score, classify it as subjective.\n",
    "\n",
    "# Function to classify subjectivity\n",
    "def is_subjective(tokens):\n",
    "    for word in tokens:\n",
    "        synsets = list(swn.senti_synsets(word))\n",
    "        if synsets:\n",
    "            sentiment = synsets[0]\n",
    "            if sentiment.pos_score() > 0 or sentiment.neg_score() > 0:\n",
    "                return True  # Returns Subjective\n",
    "    return False  # Returns Objective\n",
    "\n",
    "\n",
    "# Function to extract semantic associations\n",
    "def semantic_association(tokens):\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    associations = []\n",
    "    for token in doc:\n",
    "        if token.pos_ in ['VERB', 'ADJ','NOUN','ADV']:\n",
    "            associations.append((token.text, token.head.text))\n",
    "    return associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b360ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify polarity\n",
    "def polarity_classification(associations):\n",
    "    sentiment_score = 0\n",
    "    for word, subject in associations:\n",
    "        synsets = list(swn.senti_synsets(word))\n",
    "        if synsets:\n",
    "            sentiment = synsets[0]\n",
    "            sentiment_score += sentiment.pos_score() - sentiment.neg_score()\n",
    "    return 4 if sentiment_score > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb8baeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1419463</th>\n",
       "      <td>4</td>\n",
       "      <td>2057973787</td>\n",
       "      <td>Sat Jun 06 14:01:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Armano</td>\n",
       "      <td>@jbell99 hey, don't hold back, go for it. That...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908428</th>\n",
       "      <td>4</td>\n",
       "      <td>1696215889</td>\n",
       "      <td>Mon May 04 07:50:47 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SickzEight</td>\n",
       "      <td>It's a good day! The lake is a mirror, the kid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83816</th>\n",
       "      <td>0</td>\n",
       "      <td>1753447295</td>\n",
       "      <td>Sun May 10 01:41:01 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ncallender</td>\n",
       "      <td>Is feeling that my heart is in two different p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935282</th>\n",
       "      <td>4</td>\n",
       "      <td>1792695875</td>\n",
       "      <td>Wed May 13 23:56:36 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>neenz</td>\n",
       "      <td>@CindySJ We're fine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484105</th>\n",
       "      <td>4</td>\n",
       "      <td>2067606205</td>\n",
       "      <td>Sun Jun 07 12:38:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jaybranch</td>\n",
       "      <td>@fionajc3 It's quite cool.... and very easy.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128598</th>\n",
       "      <td>4</td>\n",
       "      <td>1975377890</td>\n",
       "      <td>Sat May 30 15:01:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Tammy09x</td>\n",
       "      <td>@ReeceNoi aww :-| will you be coming back to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223253</th>\n",
       "      <td>4</td>\n",
       "      <td>1990386823</td>\n",
       "      <td>Mon Jun 01 04:43:51 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>linabrynn</td>\n",
       "      <td>for once, im pretty glad its monday  exactly t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466672</th>\n",
       "      <td>4</td>\n",
       "      <td>2064506512</td>\n",
       "      <td>Sun Jun 07 06:27:21 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>chrisoakley</td>\n",
       "      <td>@kkfla737 Very good, thank you!  That said, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512360</th>\n",
       "      <td>0</td>\n",
       "      <td>2190121240</td>\n",
       "      <td>Tue Jun 16 01:49:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>MorgaineNYC</td>\n",
       "      <td>@kittyy79 Sadly, my client had a different idea.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189098</th>\n",
       "      <td>4</td>\n",
       "      <td>1983452222</td>\n",
       "      <td>Sun May 31 13:10:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>itsM0RGAN</td>\n",
       "      <td>baccalaurate? that's a complete guess</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity          id                          date     query  \\\n",
       "1419463         4  2057973787  Sat Jun 06 14:01:13 PDT 2009  NO_QUERY   \n",
       "908428          4  1696215889  Mon May 04 07:50:47 PDT 2009  NO_QUERY   \n",
       "83816           0  1753447295  Sun May 10 01:41:01 PDT 2009  NO_QUERY   \n",
       "935282          4  1792695875  Wed May 13 23:56:36 PDT 2009  NO_QUERY   \n",
       "1484105         4  2067606205  Sun Jun 07 12:38:31 PDT 2009  NO_QUERY   \n",
       "1128598         4  1975377890  Sat May 30 15:01:55 PDT 2009  NO_QUERY   \n",
       "1223253         4  1990386823  Mon Jun 01 04:43:51 PDT 2009  NO_QUERY   \n",
       "1466672         4  2064506512  Sun Jun 07 06:27:21 PDT 2009  NO_QUERY   \n",
       "512360          0  2190121240  Tue Jun 16 01:49:44 PDT 2009  NO_QUERY   \n",
       "1189098         4  1983452222  Sun May 31 13:10:58 PDT 2009  NO_QUERY   \n",
       "\n",
       "                user                                               text  \n",
       "1419463       Armano  @jbell99 hey, don't hold back, go for it. That...  \n",
       "908428    SickzEight  It's a good day! The lake is a mirror, the kid...  \n",
       "83816     ncallender  Is feeling that my heart is in two different p...  \n",
       "935282         neenz                              @CindySJ We're fine.   \n",
       "1484105    jaybranch  @fionajc3 It's quite cool.... and very easy.  ...  \n",
       "1128598     Tammy09x  @ReeceNoi aww :-| will you be coming back to w...  \n",
       "1223253    linabrynn  for once, im pretty glad its monday  exactly t...  \n",
       "1466672  chrisoakley  @kkfla737 Very good, thank you!  That said, it...  \n",
       "512360   MorgaineNYC  @kittyy79 Sadly, my client had a different idea.   \n",
       "1189098    itsM0RGAN             baccalaurate? that's a complete guess   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_path = \"Twitter_data.csv\"  \n",
    "data = pd.read_csv(dataset_path, sep=\",\",encoding='ISO-8859-1',  names=[\"polarity\", \"id\", \"date\", \"query\", \"user\", \"text\"])\n",
    "data = data.sample(n=50000)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "910af117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to classify text as subjective or objective based on SentiWordNet.\n",
    "# For each token, check its positive and negative sentiment scores using SentiWordNet.\n",
    "# If a word has a positive or negative score, classify it as subjective.\n",
    "\n",
    "# Preprocess tweets\n",
    "data = data[[\"polarity\", \"text\"]]\n",
    "data[\"tokens\"] = data[\"text\"].apply(preprocess_tweet)\n",
    "\n",
    "# Apply custom sentiment system\n",
    "data[\"subjective\"] = data[\"tokens\"].apply(is_subjective)\n",
    "data[\"associations\"] = data[\"tokens\"].apply(semantic_association)\n",
    "data[\"predicted_polarity\"] = data[\"associations\"].apply(polarity_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "405c3932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1419463    [(hold, hold), (go, hold), (s, hold), (youtube...\n",
       "908428     [(good, day), (day, happy), (happy, get), (get...\n",
       "83816      [(feeling, ve), (heart, feeling), (different, ...\n",
       "935282                                        [(fine, fine)]\n",
       "1484105    [(quite, cool), (cool, info), (easy, visit), (...\n",
       "                                 ...                        \n",
       "147561     [(stop, stop), (asking, stop), (play, football...\n",
       "47059      [(condom, aid), (aid, thing), (thing, m), (tru...\n",
       "184243     [(there, nothing), (available, nothing), (phx,...\n",
       "265997     [(seen, training), (training, starting), (star...\n",
       "903268                                           [(sho, fo)]\n",
       "Name: associations, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"associations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cb836e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>subjective</th>\n",
       "      <th>associations</th>\n",
       "      <th>predicted_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1419463</th>\n",
       "      <td>4</td>\n",
       "      <td>@jbell99 hey, don't hold back, go for it. That...</td>\n",
       "      <td>[hey, dont, hold, back, go, thats, youtube]</td>\n",
       "      <td>False</td>\n",
       "      <td>[(hold, hold), (go, hold), (s, hold), (youtube...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908428</th>\n",
       "      <td>4</td>\n",
       "      <td>It's a good day! The lake is a mirror, the kid...</td>\n",
       "      <td>[good, day, lake, mirror, kid, happy, get, cle...</td>\n",
       "      <td>True</td>\n",
       "      <td>[(good, day), (day, happy), (happy, get), (get...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83816</th>\n",
       "      <td>0</td>\n",
       "      <td>Is feeling that my heart is in two different p...</td>\n",
       "      <td>[feeling, heart, two, different, place, today,...</td>\n",
       "      <td>True</td>\n",
       "      <td>[(feeling, ve), (heart, feeling), (different, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935282</th>\n",
       "      <td>4</td>\n",
       "      <td>@CindySJ We're fine.</td>\n",
       "      <td>[fine]</td>\n",
       "      <td>True</td>\n",
       "      <td>[(fine, fine)]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484105</th>\n",
       "      <td>4</td>\n",
       "      <td>@fionajc3 It's quite cool.... and very easy.  ...</td>\n",
       "      <td>[quite, cool, easy, visit, info]</td>\n",
       "      <td>True</td>\n",
       "      <td>[(quite, cool), (cool, info), (easy, visit), (...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128598</th>\n",
       "      <td>4</td>\n",
       "      <td>@ReeceNoi aww :-| will you be coming back to w...</td>\n",
       "      <td>[aww, coming, back, waterloo, road, x]</td>\n",
       "      <td>False</td>\n",
       "      <td>[(aww, coming), (coming, coming), (back, comin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223253</th>\n",
       "      <td>4</td>\n",
       "      <td>for once, im pretty glad its monday  exactly t...</td>\n",
       "      <td>[im, pretty, glad, monday, exactly, two, month...</td>\n",
       "      <td>True</td>\n",
       "      <td>[(m, m), (pretty, glad), (glad, m), (exactly, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466672</th>\n",
       "      <td>4</td>\n",
       "      <td>@kkfla737 Very good, thank you!  That said, it...</td>\n",
       "      <td>[good, thank, said, totally, wrong, time, zone...</td>\n",
       "      <td>True</td>\n",
       "      <td>[(thank, said), (said, said), (totally, wrong)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512360</th>\n",
       "      <td>0</td>\n",
       "      <td>@kittyy79 Sadly, my client had a different idea.</td>\n",
       "      <td>[sadly, client, different, idea]</td>\n",
       "      <td>True</td>\n",
       "      <td>[(sadly, client), (client, client), (different...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189098</th>\n",
       "      <td>4</td>\n",
       "      <td>baccalaurate? that's a complete guess</td>\n",
       "      <td>[baccalaurate, thats, complete, guess]</td>\n",
       "      <td>True</td>\n",
       "      <td>[(baccalaurate, baccalaurate), (s, baccalaurat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity                                               text  \\\n",
       "1419463         4  @jbell99 hey, don't hold back, go for it. That...   \n",
       "908428          4  It's a good day! The lake is a mirror, the kid...   \n",
       "83816           0  Is feeling that my heart is in two different p...   \n",
       "935282          4                              @CindySJ We're fine.    \n",
       "1484105         4  @fionajc3 It's quite cool.... and very easy.  ...   \n",
       "1128598         4  @ReeceNoi aww :-| will you be coming back to w...   \n",
       "1223253         4  for once, im pretty glad its monday  exactly t...   \n",
       "1466672         4  @kkfla737 Very good, thank you!  That said, it...   \n",
       "512360          0  @kittyy79 Sadly, my client had a different idea.    \n",
       "1189098         4             baccalaurate? that's a complete guess    \n",
       "\n",
       "                                                    tokens  subjective  \\\n",
       "1419463        [hey, dont, hold, back, go, thats, youtube]       False   \n",
       "908428   [good, day, lake, mirror, kid, happy, get, cle...        True   \n",
       "83816    [feeling, heart, two, different, place, today,...        True   \n",
       "935282                                              [fine]        True   \n",
       "1484105                   [quite, cool, easy, visit, info]        True   \n",
       "1128598             [aww, coming, back, waterloo, road, x]       False   \n",
       "1223253  [im, pretty, glad, monday, exactly, two, month...        True   \n",
       "1466672  [good, thank, said, totally, wrong, time, zone...        True   \n",
       "512360                    [sadly, client, different, idea]        True   \n",
       "1189098             [baccalaurate, thats, complete, guess]        True   \n",
       "\n",
       "                                              associations  predicted_polarity  \n",
       "1419463  [(hold, hold), (go, hold), (s, hold), (youtube...                   0  \n",
       "908428   [(good, day), (day, happy), (happy, get), (get...                   4  \n",
       "83816    [(feeling, ve), (heart, feeling), (different, ...                   4  \n",
       "935282                                      [(fine, fine)]                   0  \n",
       "1484105  [(quite, cool), (cool, info), (easy, visit), (...                   0  \n",
       "1128598  [(aww, coming), (coming, coming), (back, comin...                   0  \n",
       "1223253  [(m, m), (pretty, glad), (glad, m), (exactly, ...                   4  \n",
       "1466672  [(thank, said), (said, said), (totally, wrong)...                   0  \n",
       "512360   [(sadly, client), (client, client), (different...                   4  \n",
       "1189098  [(baccalaurate, baccalaurate), (s, baccalaurat...                   0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e267c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed System:\n",
      "Accuracy: 0.5634\n",
      "Precision: 0.5642\n",
      "Recall: 0.5634\n",
      "F1-Score: 0.5624\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Proposed System\n",
    "proposed_accuracy = accuracy_score(data[\"polarity\"], data[\"predicted_polarity\"])\n",
    "proposed_precision = precision_score(data[\"polarity\"], data[\"predicted_polarity\"], average=\"weighted\")\n",
    "proposed_recall = recall_score(data[\"polarity\"], data[\"predicted_polarity\"], average=\"weighted\")\n",
    "proposed_f1 = f1_score(data[\"polarity\"], data[\"predicted_polarity\"], average=\"weighted\")\n",
    "\n",
    "print(\"Proposed System:\")\n",
    "print(f\"Accuracy: {proposed_accuracy:.4f}\")\n",
    "print(f\"Precision: {proposed_precision:.4f}\")\n",
    "print(f\"Recall: {proposed_recall:.4f}\")\n",
    "print(f\"F1-Score: {proposed_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2133702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74      5015\n",
      "           4       0.73      0.77      0.75      4985\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.74      0.74     10000\n",
      "weighted avg       0.74      0.74      0.74     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning benchmarking\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
    "X = vectorizer.fit_transform(data[\"tokens\"])\n",
    "y = data[\"polarity\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_preds = lr.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, lr_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed148c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74      5015\n",
      "           4       0.74      0.72      0.73      4985\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.74      0.74     10000\n",
      "weighted avg       0.74      0.74      0.74     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_preds = nb.predict(X_test)\n",
    "print(\"Naive Bayes:\\n\", classification_report(y_test, nb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16d37295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74      5015\n",
      "           4       0.73      0.78      0.76      4985\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.75      0.75     10000\n",
      "weighted avg       0.75      0.75      0.75     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_preds = svm.predict(X_test)\n",
    "print(\"Support Vector Machine:\\n\", classification_report(y_test, svm_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
